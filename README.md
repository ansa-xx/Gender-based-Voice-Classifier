# ðŸŽ™ï¸ Gender Classification from Voice using Whisper & CNN

![Python](https://img.shields.io/badge/Python-3.9-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-1.13+-ee4c2c.svg)
![Whisper](https://img.shields.io/badge/Whisper-OpenAI-blueviolet)

This project performs **gender classification (Male / Female)** using audio samples. It leverages **OpenAI's Whisper** model to extract `log-mel spectrograms`, which are then fed into a **Convolutional Neural Network (CNN)** for classification.

### ðŸ” Use-Cases:
- ðŸŽ¯ Content recommendation
- ðŸ” Voice-based parental controls
- ðŸ“Š Audience analysis
- ðŸ” Voice-based personalization systems

---

## ðŸ“ Project Structure

gender_classifier/
â”œâ”€â”€ audio/ # Raw audio files organized by gender
â”‚ â”œâ”€â”€ male/
â”‚ â”œâ”€â”€ female/
â”‚ â””â”€â”€ kid/
â”œâ”€â”€ data/ # Generated mel-spectrogram images (128x128)
â”‚ â”œâ”€â”€ male/
â”‚ â”œâ”€â”€ female/
â”‚ â””â”€â”€ kid/
â”œâ”€â”€ save_mel_images.py # Converts audio to mel-spectrogram PNGs
â”œâ”€â”€ train_gender.py # Training script for CNN model
â”œâ”€â”€ predict_gender.py # Predict gender for a single audio file
â”œâ”€â”€ batch_predict.py # Predict gender for a folder of audio files
â””â”€â”€ best_gender_cnn.pth # Trained model weights (PyTorch)

---

## âš™ï¸ How to Run

> âœ… **Important:** Update folder and file paths in scripts based on your local setup or environment.

### ðŸ”¹ Step 1: Preprocess Audio to Mel-Spectrograms
This will convert `.wav` or `.mp3` files from `audio/` into 128x128 mel-spectrogram images stored in the `data/` directory.
```bash
python save_mel_images.py
```

### ðŸ”¹ Step 2: Train the Model
This script trains a CNN model and saves the trained weights as `best_gender_cnn.pth`.
```bash
python train_gender.py
```

### ðŸ”¹ Step 3: Predict Gender of a Single Audio File
This script classifies a single audio file
```bash
python predict_gender.py --input path_to_audio.wav
```

### ðŸ”¹ Step 4: Batch Predict
This script classifies all audio files in a folder.
```bash
python batch_predict.py --input path_to_audio.wav
```
